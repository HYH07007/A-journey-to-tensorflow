import tensorflow as tf
from tf.examples.tutorials.mnist import input_data //Loading input_data.py

mnist=input_data.read_data_sets("MNIST_data/",one_hot=True) //Creating a file named "MNIST_data" and download the data in it. Code in one_hot.

x=tf.placeholder(dtype,shape,name) //Creating an operation to input values.

x=tf.Variable(initial value,name)  //Declaring a variable op.

y=tf.nn.softmax(logits,axis=None,name=None,dim=None) 
//softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)

tf.matmul(a,b,transpose_a=False,transpose_b=False,adjoint_a=False,adjoint_b=False,a_is_sparse=False,b_is_sparse=False,name=None)
//a: Tensor of type float16, float32, float64, int32, complex64, complex128 and rank > 1.
b: Tensor with same type and rank as a.
transpose_a: If True, a is transposed before multiplication.
transpose_b: If True, b is transposed before multiplication.
adjoint_a: If True, a is conjugated and transposed before multiplication.
adjoint_b: If True, b is conjugated and transposed before multiplication.
a_is_sparse: If True, a is treated as a sparse matrix.
b_is_sparse: If True, b is treated as a sparse matrix.
name: Name for the operation (optional).

train_step=tf.train.GradientDescentOptimize(0.01).minimize(cost function)
init=tf.global_variables_initializer()
sess=tf.Session()
sess.run(op, feed_dict+{x1: something,x2: something})

tf.argmax(input,axis=None,name=None,dimension=None,output_type=tf.int64)
//Returns the index with the largest value across axes of a tensor. (deprecated arguments)
tf.cast(x,dtype,name) //Transform tensor x into type of dtype.
